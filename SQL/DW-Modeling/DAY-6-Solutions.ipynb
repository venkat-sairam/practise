{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cba78bf-2363-44f7-8b7d-6b94c1b45426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-veya9893:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Working with Strings & Dates</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4f9573f640>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Working with Strings & Dates\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70179c65-7514-4ec0-8535-42ef3f3ae1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "(1,'Ankit',100,10000,4,39),\n",
    "(2,'Mohit',100,15000,5,48),\n",
    "(3,'Vikas',100,10000,4,37),\n",
    "(4,'Rohit',100,5000,2,16),\n",
    "(5,'Mudit',200,12000,6,55),\n",
    "(6,'Agam',200,12000,2,14),\n",
    "(7,'Sanjay',200,9000,2,13),\n",
    "(8,'Ashish',200,5000,2,12),\n",
    "(9,'Mukesh',300,6000,6,51),\n",
    "(10,'Rakesh',500,7000,6,50),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1dba47-4ce2-4479-b345-5960de4e3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"emp_id\", \"emp_name\",\"dept_id\",\"salary\", \"manager_id\", \"emp_age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432957ed-9045-478f-bb20-79f2ba4b5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee=spark.createDataFrame(data).toDF(*columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a58d94-5814-4a5d-85c1-b895138ae615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "|     1|   Ankit|    100| 10000|         4|     39|\n",
      "|     2|   Mohit|    100| 15000|         5|     48|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|\n",
      "|     4|   Rohit|    100|  5000|         2|     16|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|\n",
      "|     6|    Agam|    200| 12000|         2|     14|\n",
      "|     7|  Sanjay|    200|  9000|         2|     13|\n",
      "|     8|  Ashish|    200|  5000|         2|     12|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d829fc-771a-4abb-b77c-5638c3629e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- emp_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- manager_id: long (nullable = true)\n",
      " |-- emp_age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9ea63b-94b5-469d-8907-1ec0e8f316c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [\n",
    "(100,'Analytics'),\n",
    "(200,'IT'),\n",
    "(300,'HR'),\n",
    "(400,'Text Analytics')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1289619d-855c-4618-8112-88d4fd53d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"dep_id\",\"dep_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bd3a16-5cb1-4dbb-a540-b237a5b1cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept=spark.createDataFrame(data).toDF(*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c39b70b-de34-4eaf-b44b-8939e58e4bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|dep_id|      dep_name|\n",
      "+------+--------------+\n",
      "|   100|     Analytics|\n",
      "|   200|            IT|\n",
      "|   300|            HR|\n",
      "|   400|Text Analytics|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcd3ca4-c3a6-4635-86b7-24059b59fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, expr, current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5acb0-a032-4900-9d11-6b99518b0361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac137dd-ba8f-4770-b9d6-ee22e2dc48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "|     1|   Ankit|    100| 10000|         4|     39|\n",
      "|     2|   Mohit|    100| 15000|         5|     48|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|\n",
      "|     4|   Rohit|    100|  5000|         2|     16|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|\n",
      "|     6|    Agam|    200| 12000|         2|     14|\n",
      "|     7|  Sanjay|    200|  9000|         2|     13|\n",
      "|     8|  Ashish|    200|  5000|         2|     12|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|\n",
      "+------+--------+-------+------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92e89ae3-2496-4768-9361-ad7af5a42721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, date_sub, col, datediff, year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c0177b-c744-4c55-8aba-6441386bf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = employee.withColumn(\"dob\", date_sub(current_date(), (col(\"emp_age\") * 365).cast(\"int\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67acb0-100b-49d3-80a4-8d1c4cedf4c0",
   "metadata": {},
   "source": [
    "### write a query to print emp name , their manager name and diffrence in their age (in days) for employees whose year of birth is before their managers year of birth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a94aa21d-17e2-435b-9d4e-ee275cbca161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = (\n",
    "    employee.alias(\"e1\").join(employee.alias(\"e2\"), on = (col(\"e1.manager_id\") ==col(\"e2.emp_id\")), how=\"inner\")\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99e0c30b-e4a0-41c3-b5a2-8b4c689ec270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|       dob|emp_id|emp_name|dept_id|salary|manager_id|emp_age|       dob|\n",
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "|     4|   Rohit|    100|  5000|         2|     16|2009-01-07|     2|   Mohit|    100| 15000|         5|     48|1977-01-15|\n",
      "|     6|    Agam|    200| 12000|         2|     14|2011-01-07|     2|   Mohit|    100| 15000|         5|     48|1977-01-15|\n",
      "|     7|  Sanjay|    200|  9000|         2|     13|2012-01-07|     2|   Mohit|    100| 15000|         5|     48|1977-01-15|\n",
      "|     8|  Ashish|    200|  5000|         2|     12|2013-01-06|     2|   Mohit|    100| 15000|         5|     48|1977-01-15|\n",
      "|     1|   Ankit|    100| 10000|         4|     39|1986-01-13|     4|   Rohit|    100|  5000|         2|     16|2009-01-07|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|1988-01-13|     4|   Rohit|    100|  5000|         2|     16|2009-01-07|\n",
      "|     2|   Mohit|    100| 15000|         5|     48|1977-01-15|     5|   Mudit|    200| 12000|         6|     55|1970-01-17|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|1970-01-17|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|1974-01-16|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|1975-01-16|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9614d8b9-8c79-44c6-bfca-d081c73d32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_details = (\n",
    "    df_joined.where(year(col(\"e1.dob\")) < year(col(\"e2.dob\")))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3695e07-742e-4982-87f4-d2d4a924991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "|emp_id|emp_name|dept_id|salary|manager_id|emp_age|       dob|emp_id|emp_name|dept_id|salary|manager_id|emp_age|       dob|\n",
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "|     1|   Ankit|    100| 10000|         4|     39|1986-01-13|     4|   Rohit|    100|  5000|         2|     16|2009-01-07|\n",
      "|     3|   Vikas|    100| 10000|         4|     37|1988-01-13|     4|   Rohit|    100|  5000|         2|     16|2009-01-07|\n",
      "|     5|   Mudit|    200| 12000|         6|     55|1970-01-17|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "|     9|  Mukesh|    300|  6000|         6|     51|1974-01-16|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "|    10|  Rakesh|    500|  7000|         6|     50|1975-01-16|     6|    Agam|    200| 12000|         2|     14|2011-01-07|\n",
      "+------+--------+-------+------+----------+-------+----------+------+--------+-------+------+----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_details.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38976fe4-9162-4710-b8b2-7dbe08b8f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_final=(\n",
    "    emp_details\n",
    "    .select(\n",
    "        col(\"e1.emp_name\"),\n",
    "        col(\"e2.emp_name\").alias(\"Manager_name\"), \n",
    "        datediff(col(\"e2.dob\"), col(\"e1.dob\")).alias(\"diff_in_days\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a952e4e6-e067-41a3-8efd-53375e1597c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|emp_name|Manager_name|diff_in_days|\n",
      "+--------+------------+------------+\n",
      "|   Ankit|       Rohit|        8395|\n",
      "|   Vikas|       Rohit|        7665|\n",
      "|   Mudit|        Agam|       14965|\n",
      "|  Mukesh|        Agam|       13505|\n",
      "|  Rakesh|        Agam|       13140|\n",
      "+--------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455cff8-8a7c-4f2b-9622-6929217c038f",
   "metadata": {},
   "source": [
    "### write a query to find subcategories who never had any return orders in the month of november (irrespective of years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae512e5b-7dd7-4ad7-9964-13eeda4cefaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1c9bb6f-31fd-4a6a-a5db-a729c360a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the `orders` DataFrame\n",
    "orders_data = [\n",
    "    (1, \"Electronics\", \"2023-11-05\"),\n",
    "    (2, \"Furniture\", \"2023-11-15\"),\n",
    "    (3, \"Electronics\", \"2023-10-10\"),\n",
    "    (4, \"Furniture\", \"2023-11-20\"),\n",
    "    (5, \"Clothing\", \"2023-11-25\"),\n",
    "    (6, \"Clothing\", \"2023-12-01\"),\n",
    "]\n",
    "orders_columns = [\"order_id\", \"sub_category\", \"order_date\"]\n",
    "\n",
    "orders_df = spark.createDataFrame(orders_data, schema=orders_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20012264-751d-4b85-96b4-961e7cf907a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the `returns` DataFrame\n",
    "returns_data = [\n",
    "    (1, \"Defective\"),\n",
    "]\n",
    "returns_columns = [\"order_id\", \"return_reason\"]\n",
    "\n",
    "returns_df = spark.createDataFrame(returns_data, schema=returns_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a619c92-a5ce-4ee1-8f6a-b62b74e656ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_returns_joined_df=orders_df.alias(\"o\").join(returns_df.alias(\"r\"), on=(col('o.order_id') == col('r.order_id')), how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3bd4f28f-9e97-45a7-82cc-a6c21afc21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+--------+-------------+\n",
      "|order_id|sub_category|order_date|order_id|return_reason|\n",
      "+--------+------------+----------+--------+-------------+\n",
      "|       5|    Clothing|2023-11-25|    null|         null|\n",
      "|       6|    Clothing|2023-12-01|    null|         null|\n",
      "|       3| Electronics|2023-10-10|    null|         null|\n",
      "|       1| Electronics|2023-11-05|       1|    Defective|\n",
      "|       2|   Furniture|2023-11-15|    null|         null|\n",
      "|       4|   Furniture|2023-11-20|    null|         null|\n",
      "+--------+------------+----------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_returns_joined_df.sort(col(\"sub_category\"), col(\"order_date\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0e9b1-27f4-40c5-a826-d6eff02a0f5c",
   "metadata": {},
   "source": [
    "### Subcategories with zero returned orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3dc213f-0eca-4908-ba10-be646afcefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|sub_category|return_count|\n",
      "+------------+------------+\n",
      "|    Clothing|           0|\n",
      "|   Furniture|           0|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "(\n",
    "    orders_returns_joined_df\n",
    "    .groupby(\"sub_category\")\n",
    "    .agg(count(\"return_reason\").alias(\"return_count\"))\n",
    "    .where(col(\"return_count\")==0)\n",
    "    .select(\"sub_category\", \"return_count\").show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78c38b-b008-46b7-b53d-d3532dee3b91",
   "metadata": {},
   "source": [
    "### subcategories with zero returned orders in November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dcc5db30-8c34-4a6a-90d4-59fa8d804847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|month(order_date)|\n",
      "+-----------------+\n",
      "|               11|\n",
      "|               10|\n",
      "|               11|\n",
      "|               12|\n",
      "|               11|\n",
      "|               11|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_returns_joined_df.select(month(col(\"order_date\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0037136c-aab7-40c3-b71e-7b5b5abcb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month\n",
    "november_returned_orders_df=(\n",
    "    orders_returns_joined_df\n",
    "    .where(month(col(\"order_date\"))==11)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29c3009f-18a7-4a00-9f04-39e2aea244be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+--------+-------------+\n",
      "|order_id|sub_category|order_date|order_id|return_reason|\n",
      "+--------+------------+----------+--------+-------------+\n",
      "|       5|    Clothing|2023-11-25|    null|         null|\n",
      "|       1| Electronics|2023-11-05|       1|    Defective|\n",
      "|       2|   Furniture|2023-11-15|    null|         null|\n",
      "|       4|   Furniture|2023-11-20|    null|         null|\n",
      "+--------+------------+----------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "november_returned_orders_df.orderBy(\"sub_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb015558-43af-403b-9c25-d89d9414ac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|sub_category|return_reason_count|\n",
      "+------------+-------------------+\n",
      "|    Clothing|                  0|\n",
      "|   Furniture|                  0|\n",
      "+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    november_returned_orders_df\n",
    "    .groupby(\"sub_category\")\n",
    "    .agg(count(\"return_reason\").alias(\"return_reason_count\"))\n",
    "    .where(col(\"return_reason_count\")==0)\n",
    "    .show()\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d23f2-37f8-4302-94cd-32d468cfd6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
