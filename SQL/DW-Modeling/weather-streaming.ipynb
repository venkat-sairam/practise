{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f6492c-f92f-4e0f-b5c9-b2437e8a7445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4c45e465cbfe:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Working with Strings & Dates</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f68843d93c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Working with Strings & Dates\")\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True)\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:azure-eventhubs-spark_2.12:2.3.21\") \\\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a620f-4a96-4422-b757-9db8719b5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1116b543-e4a6-4278-9cac-baa1dcff552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8aa33d-efd2-414d-bdde-9e28c4dee8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import time\n",
    "\n",
    "# Sample data\n",
    "data = [Row(id=i, message=f\"Message {i}\", timestamp=int(time.time())) for i in range(100)]\n",
    "df = spark.createDataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a9d528-2270-41cf-b057-1f4ca7037abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-eventhub in /opt/conda/lib/python3.10/site-packages (5.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from azure-eventhub) (4.12.2)\n",
      "Requirement already satisfied: azure-core>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from azure-eventhub) (1.32.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from azure-core>=1.27.0->azure-eventhub) (2.28.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from azure-core>=1.27.0->azure-eventhub) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.27.0->azure-eventhub) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.27.0->azure-eventhub) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.27.0->azure-eventhub) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.27.0->azure-eventhub) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-eventhub --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbf651c-9b69-4212-881f-c1742ac30e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbd2e60-ba61-446d-b0ec-82fabd280b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3520b7a-19c9-42dd-8345-8b72f6781832",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer  = EventHubProducerClient.from_connection_string(\n",
    "     conn_str=connection_string,\n",
    "    eventhub_name=\"weather-streaming-eventhub\"  # Replace with your Event Hub name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f24ae5-0555-48b5-93a8-2f441c28dbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.eventhub._producer_client.EventHubProducerClient at 0x7f67bf38b670>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2628bcb-a71c-4eb1-afe7-896d0aaac1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_event(event):\n",
    "    event_data_batch = producer.create_batch()\n",
    "    event_data_batch.add(EventData(json.dumps(event)))\n",
    "    producer.send_batch(event_data_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5381f42-8843-455b-8ccd-eefc239c1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from os import getenv\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "\n",
    "api_key = getenv(\"OPENWEATHER_API_KEY\", \"b8f10c8c959340f989701949250801\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78970adb-2c38-43c0-adca-2c944c497485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function as a base to get the weather data\n",
    "# This uses the base url and takes the city and endpoint as an argument\n",
    "\n",
    "def get_endpoint_weather_data(city, endpoint, days=None):\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "   \n",
    "    if days:\n",
    "        target_url = f\"{base_url}{endpoint}?key={api_key}&q={city}&days={days}\"\n",
    "    else:\n",
    "        target_url = f\"{base_url}{endpoint}?key={api_key}&q={city}\"\n",
    "\n",
    "    # print(\"Target URL\", target_url)\n",
    "    response = requests.get(target_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Error in GET request\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8ccc9-4c21-46c4-990b-0ec828fdf865",
   "metadata": {},
   "source": [
    "## Get Current Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eafd156-8df8-4e9f-9ee2-ba1581e66376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather_data(city=\"Boulder\"):\n",
    "\n",
    "    endpoint = \"current.json\"\n",
    "    data = get_endpoint_weather_data(city, endpoint)\n",
    "\n",
    "    # Extracting data\n",
    "    location = data.get(\"location\").get(\"name\")\n",
    "    region = data.get(\"location\").get(\"region\")\n",
    "    country = data.get(\"location\").get(\"country\")\n",
    "    temp_c = data.get(\"current\").get(\"temp_c\")\n",
    "    temp_f = data.get(\"current\").get(\"temp_f\")\n",
    "\n",
    "    feels_like_c = data.get(\"current\").get(\"feelslike_c\")\n",
    "    feels_like_f = data.get(\"current\").get(\"feelslike_f\")\n",
    "    \n",
    "    local_time = data.get(\"location\").get(\"localtime\")\n",
    "    last_updated_time = data.get(\"current\").get(\"last_updated\")\n",
    "    current_condition = data.get(\"current\").get(\"condition\").get(\"text\")\n",
    "\n",
    "    wind_speed_kph = data.get(\"current\").get(\"wind_kph\")\n",
    "    wind_speed_mph = data.get(\"current\").get(\"wind_mph\")\n",
    "    wind_direction = data.get(\"current\").get(\"wind_dir\")\n",
    "\n",
    "    humidity = data.get(\"current\").get(\"humidity\")\n",
    "\n",
    "    precipitation = data.get(\"current\").get(\"precip_mm\")\n",
    "\n",
    "    uv = data.get(\"current\").get(\"uv\")\n",
    "\n",
    "    # return the extracted data as a dictionary\n",
    "    weather_data = {\n",
    "        \"location\": location,\n",
    "        \"region\": region,\n",
    "        \"country\": country,\n",
    "        \"temp_c\": temp_c,\n",
    "        \"temp_f\": temp_f,\n",
    "        \"feels_like_c\": feels_like_c,\n",
    "        \"feels_like_f\": feels_like_f,\n",
    "        \"local_time\": local_time,\n",
    "        \"last_updated_time\": last_updated_time,\n",
    "        \"current_condition\": current_condition,\n",
    "        \"wind_speed_kph\": wind_speed_kph,\n",
    "        \"wind_speed_mph\": wind_speed_mph,\n",
    "        \"wind_direction\": wind_direction,\n",
    "        \"humidity\": humidity,\n",
    "        \"precipitation\": precipitation,\n",
    "        \"uv\": uv\n",
    "    }\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc058fe-b0c0-4ca6-a7db-3ef2dc68c9a9",
   "metadata": {},
   "source": [
    "## Get Alerts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49eb48e7-a125-4ff5-a26b-9db02edbd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alerts_data(city=\"Boulder\"):\n",
    "\n",
    "    endpoint = \"alerts.json\"\n",
    "\n",
    "    data = get_endpoint_weather_data(city, endpoint)\n",
    "\n",
    "    # Check if there are any alerts\n",
    "    alerts_exist = data.get(\"alerts\").get(\"alert\")\n",
    " \n",
    "    if len(alerts_exist) == 0:\n",
    "        return {\n",
    "            \"alerts\": \"No alerts for this location\"\n",
    "        }\n",
    "    return data.get(\"alerts\").get(\"alert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b89b86-2be7-4300-8310-461dc960f2f0",
   "metadata": {},
   "source": [
    "## Get forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "638915ef-2c1d-4ba8-a7d7-df71e940b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "### Define a function to get the forecast data\n",
    "def get_forecasted_data(days:int, city=\"Boulder\")-> List[dict]:\n",
    "\n",
    "    endpoint = \"forecast.json\"\n",
    "\n",
    "    data = get_endpoint_weather_data(city, endpoint, days=2)\n",
    "\n",
    "    forecasted_data = data.get(\"forecast\").get(\"forecastday\")\n",
    "    \n",
    "    # print(f\"Forecasted data for the next {days} days\", len(forecasted_data))\n",
    "    # Extracting the forecasted data for the next 3 days\n",
    "    # forecasted_data = forecasted_data[:days]\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"date\": day.get(\"date\"),\n",
    "            \"day_condition\": day.get(\"day\").get(\"condition\").get(\"text\"),\n",
    "            \"max_temp_c\": day.get(\"day\").get(\"maxtemp_c\"),\n",
    "            \"min_temp_c\": day.get(\"day\").get(\"mintemp_c\"),\n",
    "            \"max_temp_f\": day.get(\"day\").get(\"maxtemp_f\"),\n",
    "            \"min_temp_f\": day.get(\"day\").get(\"mintemp_f\"),\n",
    "            \"precipitation\": day.get(\"day\").get(\"totalprecip_mm\"),\n",
    "            \"wind_speed_kph\": day.get(\"day\").get(\"maxwind_kph\"),\n",
    "            \"wind_speed_mph\": day.get(\"day\").get(\"maxwind_mph\"),\n",
    "            \"humidity\": day.get(\"day\").get(\"avghumidity\"),\n",
    "            \"snow_cm\": day.get(\"day\").get(\"totalsnow_cm\"),\n",
    "            \"uv\": day.get(\"day\").get(\"uv\"),\n",
    "            \"chances_of_rain\": day.get(\"day\").get(\"daily_chance_of_rain\"),\n",
    "            \"chances_of_snow\": day.get(\"day\").get(\"daily_chance_of_snow\"),\n",
    "        }\n",
    "        for day in forecasted_data\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aa72d-2179-4b72-b812-7deebe3f71f0",
   "metadata": {},
   "source": [
    "## Flatten Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49a1769-d690-45c6-b228-682e200fe11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge the functions into one main function\n",
    "### This will be the flattened dictionary that will be used to store the data\n",
    "\n",
    "def flatten_data():\n",
    "    current_weather_data = get_current_weather_data(city=\"Boulder\")\n",
    "    alerts_data = get_alerts_data(city=\"Boulder\")\n",
    "    forecasted_data = get_forecasted_data(days=3, city=\"Boulder\")\n",
    "\n",
    "    location = current_weather_data.get(\"location\", {})\n",
    "    region = current_weather_data.get(\"region\", {})\n",
    "    country=current_weather_data.get(\"country\", {})\n",
    "    current_temp_c = current_weather_data.get(\"temp_c\", {})\n",
    "    current_temp_f=current_weather_data.get(\"temp_f\", {})\n",
    "    current_local_time = current_weather_data.get(\"local_time\", {})\n",
    "    current_humidity = current_weather_data.get(\"humidity\", {})\n",
    "    current_precipitation = current_weather_data.get(\"precipitation\", {})\n",
    "    current_uv_index = current_weather_data.get(\"uv\", {})\n",
    "    alerts_info = alerts_data.get(\"alerts\", {})\n",
    "    forecasted_data = [\n",
    "       {\n",
    "           \"forecasted_date\": day.get(\"date\", {}),\n",
    "            \"forecasted_day_condition\": day.get(\"day_condition\", {}),\n",
    "            \"forecasted_chances_of_rain\": day.get(\"chances_of_rain\", {}),\n",
    "            \"forecasted_chances_of_snow\": day.get(\"chances_of_snow\", {}),\n",
    "            \"forecasted_wind_speed_kph\": day.get(\"wind_speed_kph\", {}),\n",
    "            \"forecasted_precipitation\": day.get(\"precipitation\", {}),\n",
    "            \"forecasted_max_temp_c\": day.get(\"max_temp_c\", {}),\n",
    "           \"forecasted_min_temp_c\": day.get(\"min_temp_c\", {}),\n",
    "           \"forecasted_uv_index\": day.get(\"uv\", {})\n",
    "           \n",
    "       }\n",
    "        for day in forecasted_data\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"region\": region,\n",
    "        \"country\": country,\n",
    "        \"current_temp_c\": current_temp_c,\n",
    "        \"current_temp_f\": current_temp_f,\n",
    "        \"current_local_time\": current_local_time,\n",
    "        \"current_humidity\": current_humidity,\n",
    "        \"current_precipitation\": current_precipitation,\n",
    "        \"current_uv_index\": current_uv_index,\n",
    "        \"alerts_info\": alerts_info,\n",
    "        \"forecasted_data\": forecasted_data\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68be3f3-bc6b-468e-878d-f37d8f556d4d",
   "metadata": {},
   "source": [
    "## Stream the weather data to events Hub in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d494fc-f739-48f4-900f-4853ef31e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_batch_data(batch_df, batch_id):\n",
    "    try:\n",
    "        print(\"Processing the batch id: {}\".format(batch_id))\n",
    "\n",
    "        # Flatten the data\n",
    "        flattened_data = flatten_data()\n",
    "        send_event(flattened_data)\n",
    "        print(f\"Batch {batch_id} written successfully!\")\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in processing the batch data\", e)\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1081e4da-cfea-4cd6-a421-621b7624c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = (\n",
    "            spark\n",
    "            .readStream\n",
    "            .format(\"rate\")\n",
    "            .option(\"rowsPerSecond\", 1)\n",
    "            .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49f8f475-4a74-413d-b796-4352e11f8f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the batch id: 0\n",
      "Batch 0 written successfully!\n",
      "Processing the batch id: 1\n",
      "Batch 1 written successfully!\n",
      "Processing the batch id: 2\n",
      "Batch 2 written successfully!\n",
      "Processing the batch id: 3\n",
      "Batch 3 written successfully!\n",
      "Processing the batch id: 4\n",
      "Batch 4 written successfully!\n",
      "Processing the batch id: 5\n",
      "Batch 5 written successfully!\n",
      "Processing the batch id: 6\n",
      "Batch 6 written successfully!\n",
      "Processing the batch id: 7\n",
      "Batch 7 written successfully!\n",
      "Processing the batch id: 8\n",
      "Batch 8 written successfully!\n",
      "Processing the batch id: 9\n",
      "Batch 9 written successfully!\n",
      "Processing the batch id: 10\n",
      "Batch 10 written successfully!\n",
      "Processing the batch id: 11\n",
      "Batch 11 written successfully!\n",
      "Processing the batch id: 12\n",
      "Batch 12 written successfully!\n",
      "Processing the batch id: 13\n",
      "Batch 13 written successfully!\n",
      "Processing the batch id: 14\n",
      "Batch 14 written successfully!\n",
      "Processing the batch id: 15\n",
      "Batch 15 written successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m             \u001b[43mstreaming_df\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteStream\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeachBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrigger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessingTime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m30 seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/streaming.py:107\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(\n",
    "            streaming_df\n",
    "            .writeStream\n",
    "            .foreachBatch(process_batch_data)\n",
    "            .trigger(processingTime=\"30 seconds\")\n",
    "            .outputMode(\"append\")\n",
    "            .start()\n",
    "            .awaitTermination()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fdcaf-4018-47f7-81bf-77fb2aa1e2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39749502-cfdd-48d8-8574-e806e2cee4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
