{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1586db-6aa7-4e63-ba7c-79952388c7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://75c4a41613a2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Writing to Multiple Sinks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc9083c4550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"Writing to Multiple Sinks\") \n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", True) \n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0')\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/postgresql-42.5.6.jar\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 8)\n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgresExample\") \\\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/postgresql-42.5.6.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f4aa07-93ce-414f-ac72-0ef6a2a9daa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark/jars/postgresql-42.5.6.jar\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.getConf().get(\"spark.jars\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d549179-fe35-4348-93b4-c46c0150ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "042af625-420b-45ad-9b46-be580ae4bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"eventId\", StringType(), True),\n",
    "    StructField(\"eventOffset\", IntegerType(), True),\n",
    "    StructField(\"eventPublisher\", StringType(), True),\n",
    "    StructField(\"customerId\", StringType(), True),\n",
    "    StructField(\"eventTime\", StringType(), True),\n",
    "    StructField(\"deviceId\", StringType(), True),\n",
    "    StructField(\"temperature\", IntegerType(), True),\n",
    "    StructField(\"measure\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create the data\n",
    "data = [\n",
    "    ('e3cb26d3-41b2-49a2-84f3-0156ed8d7502', 10001, 'device', 'CI00103','2023-01-05 11:13:53.643364', 'D001', 15, 'C', 'SUCCESS')\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7707417-2fae-4908-82a9-ce42220d1b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------+----------+--------------------+--------+-----------+-------+-------+\n",
      "|             eventId|eventOffset|eventPublisher|customerId|           eventTime|deviceId|temperature|measure| status|\n",
      "+--------------------+-----------+--------------+----------+--------------------+--------+-----------+-------+-------+\n",
      "|e3cb26d3-41b2-49a...|      10001|        device|   CI00103|2023-01-05 11:13:...|    D001|         15|      C|SUCCESS|\n",
      "+--------------------+-----------+--------------+----------+--------------------+--------+-----------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dc9776b-4a6c-43fe-928a-642c4e3c7ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    (\n",
    "        df.write\n",
    "        .mode(\"append\")  \n",
    "        .format(\"jdbc\") \n",
    "        .option(\"driver\", \"org.postgresql.Driver\")  \n",
    "        .option(\"url\", \"jdbc:postgresql://postgres:5432/db\")  \n",
    "        .option(\"dbtable\", \"public.events\") \n",
    "        .option(\"user\", \"postgres\")  \n",
    "        .option(\"password\", \"postgres\")\n",
    "        .save()\n",
    "    )\n",
    "    print(\"Data successfully written to PostgreSQL!\")\n",
    "except Exception as e:\n",
    "    print(f\"Write operation failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cea5a8c4-93b1-45fc-9973-b236a22590aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------+----------+--------------------+--------+--------+-------+-----------+\n",
      "|             eventid|eventoffset|eventpublisher|customerid|           eventtime|deviceid| measure| status|temperature|\n",
      "+--------------------+-----------+--------------+----------+--------------------+--------+--------+-------+-----------+\n",
      "|        test_event_2|       1002|    publisher2| customer2|          2025-01-02| device2|measure2|  ERROR|         24|\n",
      "|        test_event_1|       1001|    publisher1| customer1|          2025-01-01| device1|measure1|     OK|         22|\n",
      "|        test_event_2|       1002|    publisher2| customer2|          2025-01-02| device2|measure2|  ERROR|         24|\n",
      "|        test_event_1|       1001|    publisher1| customer1|          2025-01-01| device1|measure1|     OK|         22|\n",
      "|e3cb26d3-41b2-49a...|      10001|        device|   CI00103|2023-01-05 11:13:...|    D001|       C|SUCCESS|         15|\n",
      "+--------------------+-----------+--------------+----------+--------------------+--------+--------+-------+-----------+\n",
      "\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"jdbc:postgresql://postgres:5432/db\" \n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    df = spark.read.jdbc(url=url, table=\"events\", properties=properties)\n",
    "    df.show() \n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc90a61-519e-46f7-a5ab-2c47dcd225a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11684aa2-d381-46c2-8411-54887d5516fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- eventid: string (nullable = true)\n",
      " |-- eventoffset: long (nullable = true)\n",
      " |-- eventpublisher: string (nullable = true)\n",
      " |-- customerid: string (nullable = true)\n",
      " |-- eventtime: string (nullable = true)\n",
      " |-- deviceid: string (nullable = true)\n",
      " |-- measure: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- temperature: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
